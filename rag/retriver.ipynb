{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a9b35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = PyPDFLoader(\"Zain Ali Shah.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = splitter.split_documents(data)\n",
    "\n",
    "# Embeding\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())\n",
    "# export db as retriver\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ded95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F6BD4B4620>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F6BC1C1A60>, root_client=<openai.OpenAI object at 0x000001F6AA8044D0>, root_async_client=<openai.AsyncOpenAI object at 0x000001F6BCA01BE0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57eb8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only provided context. Think step by step before providing a detailed answer.\\nI will tip you $1000 if the user satisfy with your answer.\\n\\n<context>\\n{context}\\n<context/>\\n\\nQuestion: {input}\\n\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Prompt Template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. Think step by step before providing a detailed answer.\n",
    "I will tip you $1000 if the user is satisfied with your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695e514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only provided context. Think step by step before providing a detailed answer.\\nI will tip you $1000 if the user satisfy with your answer.\\n\\n<context>\\n{context}\\n<context/>\\n\\nQuestion: {input}\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F6BD4B4620>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F6BC1C1A60>, root_client=<openai.OpenAI object at 0x000001F6AA8044D0>, root_async_client=<openai.AsyncOpenAI object at 0x000001F6BCA01BE0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chains\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "246462a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine the company Syed Zain Ali Shah is currently working for, we need to identify the most recent position he holds. \\n\\n1. According to the context, Zain is currently working as a Frontend Engineer at Kodexo Labs.\\n2. His tenure at Kodexo Labs started in January 2025 and is listed as \"Present,\" indicating he is currently employed there.\\n3. His previous role was at Techsol LLC as a Full Stack Developer, which ended in December 2024.\\n\\nTherefore, based on the latest information provided, Syed Zain Ali Shah is currently working at Kodexo Labs as a Frontend Engineer.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retriver chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "retriever_chain = create_retrieval_chain(retriever=retriever,combine_docs_chain=document_chain)\n",
    "\n",
    "\n",
    "response = retriever_chain.invoke({\"input\":\"In which company is zain currently working\"})\n",
    "response[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
